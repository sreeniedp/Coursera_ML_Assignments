{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "python-machine-learning",
      "graded_item_id": "5yX9Z",
      "launcher_item_id": "eqnV3",
      "part_id": "Msnj0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Assignment+3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreeniedp/Coursera_ML_Assignments/blob/master/Assignment%2B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UwEBx6tjEW5",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "_You are currently looking at **version 1.2** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STw9R07ujEW8",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3 - Evaluation\n",
        "\n",
        "In this assignment you will train several models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud).\n",
        " \n",
        "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
        " \n",
        "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0gtkKINjEW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQYhmiPwjEXF",
        "colab_type": "text"
      },
      "source": [
        "### Question 1\n",
        "Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
        "\n",
        "*This function should return a float between 0 and 1.* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly2vYRUojEXH",
        "colab_type": "code",
        "colab": {},
        "outputId": "4a1ca716-2c0a-4478-e7d7-b6f8aa217252"
      },
      "source": [
        "def answer_one():\n",
        "    \n",
        "    # Your code here\n",
        "    df = pd.read_csv('fraud_data.csv')\n",
        "    target=df.values[:,-1] \n",
        "    Class,Class_0_1=np.unique(target,return_counts=True)\n",
        "    Class_0_1[0]/len(target)\n",
        "    \n",
        "    return len(target[target==1])/len(target) # Return your answer\n",
        "answer_one()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.016410823768035772"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "101HVzuHjEXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('fraud_data.csv')\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bki7P5tjEXU",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
        "\n",
        "*This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9rX1eCYjEXV",
        "colab_type": "code",
        "colab": {},
        "outputId": "da6a34ef-59df-4c77-8de5-931bad0bd73d"
      },
      "source": [
        "def answer_two():\n",
        "    from sklearn.dummy import DummyClassifier\n",
        "    from sklearn.metrics import recall_score\n",
        "    \n",
        "    # Your code here\n",
        "    dmycl=DummyClassifier(\"most_frequent\").fit(X_train,y_train)\n",
        "    y_dmy_prec=dmycl.predict(X_test)\n",
        "    \n",
        "    \n",
        "    return (dmycl.score(X_test,y_test),recall_score(y_test,y_dmy_prec)) # Return your answer\n",
        "answer_two()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.98525073746312686, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ1swqmUjEXb",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
        "\n",
        "*This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC2IGPk4jEXb",
        "colab_type": "code",
        "colab": {},
        "outputId": "e439eaf4-110e-47d5-afa7-7162824e7480"
      },
      "source": [
        "def answer_three():\n",
        "    from sklearn.metrics import recall_score, precision_score\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    # Your code here\n",
        "    svm=SVC().fit(X_train,y_train)\n",
        "    y_predict=svm.predict(X_test)\n",
        "    return (svm.score(X_test,y_test),recall_score(y_test,y_predict),precision_score(y_test,y_predict)) # Return your answer\n",
        "answer_three()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.99078171091445433, 0.375, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiXRh1wKjEXf",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
        "\n",
        "*This function should return a confusion matrix, a 2x2 numpy array with 4 integers.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWEDusyjjEXf",
        "colab_type": "code",
        "colab": {},
        "outputId": "5620d571-4bf1-4c0b-e6c1-c942afb8d574"
      },
      "source": [
        "def answer_four():\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    # Your code here\n",
        "    svm=SVC(C= 1e9, gamma= 1e-07).fit(X_train,y_train)\n",
        "    y_decision=svm.decision_function(X_test)\n",
        "    thr=-220\n",
        "    y_decision[y_decision>thr ]=1\n",
        "    y_decision[y_decision !=1]=0\n",
        "    \n",
        "\n",
        "    cnf_mc=confusion_matrix(y_test,y_decision)\n",
        "    return cnf_mc# Return your answer\n",
        "answer_four()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5320,   24],\n",
              "       [  14,   66]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhMg06cjjEXj",
        "colab_type": "text"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Train a logisitic regression classifier with default parameters using X_train and y_train.\n",
        "\n",
        "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
        "\n",
        "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
        "\n",
        "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
        "\n",
        "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRSXZNahjEXj",
        "colab_type": "code",
        "colab": {},
        "outputId": "11d0aec3-d73c-404c-e4aa-9757376babee"
      },
      "source": [
        "def answer_five():\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import precision_recall_curve,roc_curve\n",
        "   \n",
        "    # Your code here\n",
        "    lgr=LogisticRegression().fit(X_train,y_train) \n",
        "    y_prop_est=lgr.decision_function(X_test)\n",
        "    pre,rec,thr=precision_recall_curve(y_test,y_prop_est)\n",
        "    recall_at_precision=rec[np.where(pre==0.75)[0][0]]\n",
        "    \n",
        "    y_prop=lgr.predict_proba(X_test)\n",
        "    fpr,tpr,thrs=roc_curve(y_test,y_prop[:,1])\n",
        "    tpr_at_fp=tpr[np.where(np.round(fpr,2)==0.16)[0][0]]\n",
        "    return (recall_at_precision,tpr_at_fp)# Return your answer\n",
        "\n",
        "answer_five()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.82499999999999996, 0.9375)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHC68J_2jEXm",
        "colab_type": "text"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
        "\n",
        "`'penalty': ['l1', 'l2']`\n",
        "\n",
        "`'C':[0.01, 0.1, 1, 10, 100]`\n",
        "\n",
        "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
        "\n",
        "|      \t| `l1` \t| `l2` \t|\n",
        "|:----:\t|----\t|----\t|\n",
        "| **`0.01`** \t|    ?\t|   ? \t|\n",
        "| **`0.1`**  \t|    ?\t|   ? \t|\n",
        "| **`1`**    \t|    ?\t|   ? \t|\n",
        "| **`10`**   \t|    ?\t|   ? \t|\n",
        "| **`100`**   \t|    ?\t|   ? \t|\n",
        "\n",
        "<br>\n",
        "\n",
        "*This function should return a 5 by 2 numpy array with 10 floats.* \n",
        "\n",
        "*Note: do not return a DataFrame, just the values denoted by '?' above in a numpy array. You might need to reshape your raw result to meet the format we are looking for.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNEH893TjEXn",
        "colab_type": "code",
        "colab": {},
        "outputId": "4d50fdd0-9947-4ac4-ad30-532884bd52ac"
      },
      "source": [
        "def answer_six():    \n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "    # Your code here\n",
        "    parameters = dict(penalty=[\"l1\", \"l2\"],\n",
        "    C=[0.01, 0.1, 1, 10, 100]) \n",
        "    model = LogisticRegression() \n",
        "    grid = GridSearchCV(model, parameters, scoring=\"recall\") \n",
        "    grid.fit(X_train, y_train) \n",
        "    l1 = [grid.cv_results_[\"mean_test_score\"][index] for index in range(0, len(grid.cv_results_['mean_test_score']), 2)] \n",
        "    l2 = [grid.cv_results_[\"mean_test_score\"][index] for index in range(1, len(grid.cv_results_[\"mean_test_score\"])+ 1, 2)]\n",
        "    \n",
        "    return np.array([l1, l2]).T# Return your answer\n",
        "answer_six()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.66666667,  0.76086957],\n",
              "       [ 0.80072464,  0.80434783],\n",
              "       [ 0.8115942 ,  0.8115942 ],\n",
              "       [ 0.80797101,  0.8115942 ],\n",
              "       [ 0.80797101,  0.80797101]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ3sPF7gjEXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the following function to help visualize results from the grid search\n",
        "#def GridSearch_Heatmap(scores):\n",
        "#  %matplotlib notebook\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "#plt.figure()\n",
        "#sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
        "#plt.yticks(rotation=0);\n",
        "\n",
        "#GridSearch_Heatmap(answer_six())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}